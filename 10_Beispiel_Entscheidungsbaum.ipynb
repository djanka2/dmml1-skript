{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b315a8a9",
   "metadata": {},
   "source": [
    "# Beispielcode Entscheidungsb채ume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1f804-6830-40be-ad3f-2b4d2d117b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 200\n",
    "plt.rcParams['figure.figsize'] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfeecdc-ec8a-4570-bfec-608c92acdfbc",
   "metadata": {},
   "source": [
    "## Beispiel 1: Entscheidungsbaum f체r das \"Rad fahren\" Beispiel aus der Vorlesung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72e813-66d5-4244-aa05-e9bd485c8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rad = pd.DataFrame({\"Wetterlage\": [\"sonnig\", \"Regen\", \"Regen\", \"Regen\", \"sonnig\", \"Regen\", \"sonnig\", \"sonnig\", \"sonnig\"],\n",
    "                   \"Schnee\": [\"Nein\", \"Nein\", \"Nein\", \"Nein\", \"Nein\", \"Nein\", \"Nein\", \"Ja\", \"Ja\"],\n",
    "                   \"Auto kaputt\": [\"Nein\", \"Nein\", \"Ja\", \"Nein\", \"Ja\", \"Ja\", \"Nein\", \"Nein\", \"Ja\"],\n",
    "                   \"Start 8:00\": [\"Nein\", \"Nein\", \"Nein\", \"Nein\", \"Nein\", \"Ja\", \"Ja\", \"Nein\", \"Nein\"],\n",
    "                   \"Rad fahren\": [\"Ja\", \"Nein\", \"Ja\", \"Nein\", \"Ja\", \"Ja\", \"Nein\", \"Nein\", \"Nein\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f71bfa-17ad-413e-81b1-bd415ad6d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Leider muss man die kategorischen Features doch One-Hot encoden, da sklearn es so will.\n",
    "X = pd.get_dummies(df_rad[[\"Wetterlage\", \"Schnee\", \"Auto kaputt\", \"Start 8:00\"]], drop_first=True)\n",
    "y = pd.get_dummies(df_rad[\"Rad fahren\"], drop_first=True)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5, random_state=42, criterion=\"entropy\")\n",
    "tree_clf.fit(X, y)\n",
    "\n",
    "plot_tree(tree_clf, feature_names=X.columns, rounded=True, filled=True, fontsize=14)\n",
    "tree_clf.score(X, y)\n",
    "\n",
    "for name, score in zip([\"Wetterlage\", \"Schnee\", \"Auto kaputt\", \"Start 8:00\"], tree_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d9636-c920-470e-b75b-2b33c6b27f2c",
   "metadata": {},
   "source": [
    "## Beispiel 2: Entscheidungsbaum und Random Forest f체r den Iris Datensatz\n",
    "Hier bietet der Random Forest keinen zus채tzlichen Performancegewinn, da bereits der Entscheidungsbaum eine perfekte Vorhersage (auf dem Test Set) liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9984c-32ac-4c3d-937f-085661c55d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "plot_tree(tree_clf,rounded=True, filled=True, fontsize=14,\n",
    "          class_names=iris.target_names, feature_names=iris.feature_names)\n",
    "\n",
    "\"\"\"\n",
    "print(\"Feature importance decision tree\")\n",
    "for name, score in zip(iris.feature_names, tree_clf.feature_importances_):\n",
    "    print(name, score)\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Feature importance random forest\")\n",
    "for name, score in zip(iris.feature_names, rf_clf.feature_importances_):\n",
    "    print(name, score)\n",
    "    \n",
    "print(f\"Accuracy Entscheidungsbaum:{accuracy_score(y_test, tree_clf.predict(X_test))}\")\n",
    "print(f\"Accuracy Random Forest:{accuracy_score(y_test, rf_clf.predict(X_test))}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ebe0a-d057-481c-aaf4-59167f457abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
