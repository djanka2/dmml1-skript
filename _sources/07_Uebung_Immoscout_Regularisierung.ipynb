{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165e560e",
   "metadata": {},
   "source": [
    "# Praxis√ºbung: Regularisierung und Hyperparametersuche\n",
    "\n",
    "*In den folgenden Aufgaben werden Sie mehrere Modelle trainieren, wobei jeder Trainingslauf --- je nach Anzahl der Features und Anzahl der Datenpunkte --- eine gewisse Zeit ben√∂tigt. Um die Modellentwicklung zu beschleunigen ist es hilfreich, zun√§chst eine zuf√§llig ausgew√§hlte Teilmenge des Datensatzes zu betrachten (z.B. 10000 Punkte), die Sie sich mittels `DataFrame.sample(10000)` erzeugen.*\n",
    "\n",
    "## ‚úè Aufgabe 1\n",
    "Wenden Sie Ridge Regression und Lasso f√ºr das Wohnungsbeispiel aus der letzten Woche an. Weiter unten finden Sie eine √ºberarbeitete, √ºbersichtlichere Variante des Immoscout Notebooks. Sie k√∂nnen aber nat√ºrlich auch ihre eigene Version aus der vorherigen √úbung benutzen.\n",
    "\n",
    "1. Skalieren Sie die Features mit dem `StandardScaler` aus `scikit-learn`. Das Skalieren sollte nach dem Aufteilen in Trainings- und Testset passieren. Schauen Sie sich dazu die Dokumentation unter https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html an.\n",
    "\n",
    "2. Trainieren Sie Modelle mit $\\ell_2$- und mit $\\ell_1$-Regularisierung (Ridge Regression und Lasso). Schauen Sie in die Dokumentation https://scikit-learn.org/stable/modules/linear_model.html, um die geeigneten Methoden daf√ºr zu finden.\n",
    "\n",
    "3. Beide Methoden haben einen Parameter `alpha`. Wie ist der Wert jeweils zu interpretieren (siehe Dokumentation)?\n",
    "    \n",
    "4. Vergleichen Sie Modelle aus der vorherigen Teilaufgabe ($R^2$ bzw.\\ Fehler auf den Trainings- bzw. Testdaten) f√ºr verschiedene Werte von `alpha`. Wie k√∂nnen Sie einen m√∂glichst \"guten\" Wert f√ºr den Parameter finden?\n",
    "    \n",
    "5. Z√§hlen Sie bei der Modellauswertung f√ºr die verschiedenen $\\ell_2$- bzw. $\\ell_1$-regularisierten Modelle zus√§tzlich die Anzahl der Koeffizienten, die ungleich Null sind. Was beobachten Sie?\n",
    "\n",
    "\n",
    "## ‚úè Aufgabe 2\n",
    "F√ºhren Sie eine Hyperparametersuche mit Kreuzvalidierung durch, indem Sie den Algorithmus aus der Vorlesung f√ºr das Immoscout Beispiel implementieren.\n",
    "Sie k√∂nnen sich herantasten, indem Sie zuerst die einfache Hyperparametersuche (ohne Kreuzvalidierung) implementieren und dann Schritt 2 des Algorithmus ersetzen.\n",
    "Benutzen Sie die KFold Klasse aus scikit-learn um sich die Datens√§tze f√ºr die Kreuzvalidierung zu erzeugen: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.htm.\n",
    "\n",
    "\n",
    "## ‚úè Aufgabe 3\n",
    "F√ºhren Sie eine nested-Cross Validation durch, um eine bessere Sch√§tzung des Testfehlers zu erhalten. D.h. anstatt *ein* Trainings- und Testset zu erzeugen (vor der Hyperparametersuche), erzeugen Sie $k$ Testsets. F√ºr jedes dieser $k$ Trainings-/Testset Paare f√ºhren Sie nun die Hyperparametersuche mit Kreuzvalidierung wie in der vorherigen Aufgabe durch. Als Resultat erhalten Sie eine Sch√§tzung des Testfehlers durch Mittelung der $k$ Testfehler und $k$ Modelle.\n",
    "\n",
    "\n",
    "## ‚úè Aufgabe 4 ü§Ø\n",
    "Zeigen Sie: F√ºr ein gegebenes $\\lambda > 0$ wird die Verlustfunktion f√ºr die Ridge Regression\n",
    "\\begin{align*}\n",
    "    L(w)&=\\sum_{i=1}^N\\left(y_i-w^Tx_i\\right)^2 + \\sum_{i=1}^p w_i^2 \\\\&= \\left\\|y-Xw\\right\\|^2 + \\lambda\\left\\|w\\right\\|^2\n",
    "\\end{align*}\n",
    "minimiert von\n",
    "\\begin{align*}\n",
    "    w=(X^TX+\\lambda I)^{-1}X^Ty,\n",
    "\\end{align*}\n",
    "wobei $I\\in\\R^{p\\times p}$ die Einheitsmatrix bezeichnet.\n",
    "\n",
    "Anleitung: Orientieren Sie sich dabei am Skript, wo das entsprechende Resultat f√ºr die lineare Regression (ohne Regularisierungsterm) hergeleitet wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5984c69f-bb7d-4bbd-b02f-b72284fa28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfaf7fef-4333-4009-ac69-9142ad497208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Daten/immo_data.csv\")\n",
    "desc = pd.read_csv(\"Daten/immo_data_column_description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4851f20-f4c7-4ab3-b727-ce537c55157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    \"\"\" Entfernen (vermeintlich) unwichtiger Spalten \"\"\"\n",
    "    return df.drop(\n",
    "        [\n",
    "            \"scoutId\",\n",
    "            \"houseNumber\",\n",
    "            \"geo_bln\",\n",
    "            \"geo_krs\",\n",
    "            \"geo_plz\",\n",
    "            \"date\",\n",
    "            \"street\",\n",
    "            \"streetPlain\",\n",
    "            \"description\",\n",
    "            \"facilities\",\n",
    "            \"regio3\",\n",
    "            \"firingTypes\",\n",
    "            \"telekomHybridUploadSpeed\",\n",
    "            \"totalRent\",\n",
    "            \"baseRentRange\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def remove_outliers(df, lower_limit=0.005, upper_limit=0.995):\n",
    "    \"\"\" Entfernen der (unteren und oberen) Ausrei√üer \"\"\"\n",
    "    dfc = df.copy()\n",
    "    columns_with_outliers = [\n",
    "        \"serviceCharge\",\n",
    "        \"yearConstructed\",\n",
    "        \"noParkSpaces\",\n",
    "        \"baseRent\",\n",
    "        \"livingSpace\",\n",
    "        \"noRooms\",\n",
    "        \"floor\",\n",
    "        \"numberOfFloors\",\n",
    "        \"heatingCosts\",\n",
    "        \"lastRefurbish\",\n",
    "    ]\n",
    "    \n",
    "    # F√ºr jede Spalte behalten wir: Daten die < (99.5%-Quantil) sind und > (0.5%-Quantil) sind ODER die NaN sind (damit befassen wir uns spaeter noch) \n",
    "    upper_limits = df[columns_with_outliers].quantile(upper_limit)\n",
    "    lower_limits = df[columns_with_outliers].quantile(lower_limit)\n",
    "    \n",
    "    for colname in columns_with_outliers:\n",
    "        col = dfc[colname]\n",
    "        dfc = dfc[\n",
    "            ((col <= upper_limits[colname]) & (col >= lower_limits[colname]))\n",
    "            | col.isna()\n",
    "        ]\n",
    "    return dfc\n",
    "\n",
    "\n",
    "def remove_rows_with_NaN_target(df):\n",
    "    \"\"\" Entfernen der Datens√§tze ohne Label\"\"\"\n",
    "    return df[df[\"baseRent\"].isna() == False]\n",
    "\n",
    "\n",
    "def impute_NaNs(df):\n",
    "    \"\"\" Ersetzen von NaNs durch Mittelwert bzw. Modus \"\"\"\n",
    "    dfc = df.copy()\n",
    "    categorical_columns = dfc.select_dtypes(exclude=np.number).columns\n",
    "    imp_freq = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "    dfc.loc[:, categorical_columns] = imp_freq.fit_transform(dfc[categorical_columns])\n",
    "\n",
    "    numeric_columns = dfc.select_dtypes(include=np.number).columns\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    dfc.loc[:, numeric_columns] = imp_mean.fit_transform(dfc[numeric_columns])\n",
    "    return dfc\n",
    "\n",
    "\n",
    "def print_evaluation(pipeline_or_model, X_train, X_test, y_train, y_test, y_train_pred, y_test_pred, feature_names):\n",
    "    \"\"\" Ausgabe von R2-Wert, MSE und MAE f√ºr Trainings- und Testset \"\"\"\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    print(\n",
    "        f\"{pipeline_or_model} Evaluation:\\n\"\n",
    "        f\"{'':6} {'R¬≤':>10} | {'MSE':>14} | {'MAE':>10} | {'rows':>8} | {'columns':>8}\\n\"\n",
    "        f\"{'Train':6} {r2_train:10.5f} | {mse_train:14.2f} | {mae_train:10.2f} | {X_train.shape[0]:8} | {X_train.shape[1]:8}\\n\"\n",
    "        f\"{'Test':6} {r2_test:10.5f} | {mse_test:14.2f} | {mae_test:10.2f} | {X_test.shape[0]:8} | {X_test.shape[1]:8}\\n\"\n",
    "    )\n",
    "    \n",
    "    # Ausgabe der ersten 10 Koeffizienten, absteigend nach Absolutbetrag sortiert\n",
    "    coefficients_lr = pd.DataFrame({\"Feature Name\": feature_names, \"Coefficient\": pipeline_or_model.coef_})\n",
    "    display(coefficients_lr.sort_values(\"Coefficient\", key=abs, ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "016fed6a-366d-41a2-83bc-e012c697c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression() Evaluation:\n",
      "               R¬≤ |            MSE |        MAE |     rows |  columns\n",
      "Train     0.84047 |       26718.59 |     106.33 |   207773 |      512\n",
      "Test      0.84079 |       27084.82 |     107.07 |    51944 |      512\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>interiorQual_luxury</td>\n",
       "      <td>3.084705e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>interiorQual_sophisticated</td>\n",
       "      <td>3.084705e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>interiorQual_normal</td>\n",
       "      <td>3.084705e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>interiorQual_simple</td>\n",
       "      <td>3.084705e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>regio1_Bremen</td>\n",
       "      <td>-1.611739e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>regio2_Bremen</td>\n",
       "      <td>1.538304e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>regio2_Bremerhaven</td>\n",
       "      <td>1.538304e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>energyEfficiencyClass_H</td>\n",
       "      <td>1.514252e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>energyEfficiencyClass_B</td>\n",
       "      <td>1.514252e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>energyEfficiencyClass_G</td>\n",
       "      <td>1.514252e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature Name   Coefficient\n",
       "66          interiorQual_luxury  3.084705e+11\n",
       "69   interiorQual_sophisticated  3.084705e+11\n",
       "67          interiorQual_normal  3.084705e+11\n",
       "68          interiorQual_simple  3.084705e+11\n",
       "28                regio1_Bremen -1.611739e+11\n",
       "132               regio2_Bremen  1.538304e+11\n",
       "133          regio2_Bremerhaven  1.538304e+11\n",
       "510     energyEfficiencyClass_H  1.514252e+11\n",
       "504     energyEfficiencyClass_B  1.514252e+11\n",
       "509     energyEfficiencyClass_G  1.514252e+11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datenvorverarbeitung\n",
    "df_reduced = drop_columns(df.sample(10000))\n",
    "df_reduced = remove_outliers(df_reduced)\n",
    "df_reduced = remove_rows_with_NaN_target(df_reduced)\n",
    "df_reduced = impute_NaNs(df_reduced)\n",
    "df_reduced = pd.get_dummies(df_reduced)\n",
    "y = df_reduced.pop(\"baseRent\")\n",
    "\n",
    "# Training-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_reduced, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training\n",
    "model_lr = linear_model.LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_train_pred = model_lr.predict(X_train)\n",
    "y_test_pred = model_lr.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print_evaluation(model_lr, X_train, X_test, y_train, y_test, y_train_pred, y_test_pred, feature_names=df_reduced.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebe02b-2e04-437d-9cf1-009089643a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297b5c1-0b93-461a-bf90-1671b13b2353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
