{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be6ae7b-a3a7-4fd0-baef-f24ebcc61d73",
   "metadata": {},
   "source": [
    "# Praxisübung: Vorhersage von Wohnungsmieten\n",
    "Ziel dieser Übung ist es, die Monatskaltmiete für eine Mietwohnung vorherzusagen anhand verschiedener Features wie Größe und Zustand der Wohnung, Nebenkosten, Bundesland etc. Laden Sie sich dafür die Dateien \"immo_data.csv\" und \"immo_data_column_description.csv\" herunter. Alternativ können Sie sich die Datei immo_data.csv hier herunterladen: https://www.kaggle.com/corrieaar/apartment-rental-offers-in-germany (Account benötigt).\n",
    "\n",
    "Die Daten stammen von Immoscout24, der größten Immobilienplattform in Deutschland. Immoscout24 bietet sowohl Miet- als auch Kaufobjekte an, allerdings enthalten die Daten nur Angebote für Mietobjekte. Zu einem bestimmten Zeitpunkt wurden alle verfügbaren Angebote von der Website abgefragt und gespeichert. Dieser Vorgang wurde dreimal wiederholt, so dass der Datensatz Angebote aus den Zeiträumen 2018-09-22, 2019-05-10 und 2019-10-08 enthält.\n",
    "\n",
    "Der Datensatz enthält die meisten wichtigen Eigenschaften, wie z.B. die Größe der Wohnfläche, die Miete, sowohl Kaltmiete als auch Gesamtmiete (falls zutreffend), die Lage (Straße und Hausnummer, falls vorhanden, Postleitzahl und Bundesland), Energieart usw. Außerdem gibt es zwei Variablen, die längere Freitextbeschreibungen enthalten: Beschreibung mit einem Text, der das Angebot beschreibt, und Ausstattung mit einer Beschreibung aller verfügbaren Einrichtungen, der neuesten Renovierung usw. Die Datumsspalte wurde hinzugefügt, um den Zeitpunkt des Scrapings anzugeben.\n",
    "\n",
    "Wir möchten unser Wissen über lineare Regression und Datenanalyse an diesem Datensatz testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150fb200-f896-4b7e-b661-685019b7d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364906b-ce18-4703-be9f-f38deaf20f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"Daten/immo_data.csv\")\n",
    "desc = pd.read_csv(\"Daten/immo_data_column_description.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d32ef-fca4-4c05-a459-bed14963a292",
   "metadata": {},
   "source": [
    "Spaltenbeschreibungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ff03d-f2bd-4f82-9ab2-80cdc92b88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37498e-9622-46f6-952f-c6ad6cab53e9",
   "metadata": {},
   "source": [
    "Aus der Liste der Beschreibungen fallen uns einige Attribute auf, die doppelt auftreten oder (wahrscheinlich) keine Vorhersagekraft haben (eigentlich müsste man das verifizieren!). Diese schließen wir direkt aus, indem wir die \"drop\" Methode des DataFrame aufrufen und die entsprechenden Spaltennamen übergeben. Das Argument errors=\"ignore\" besagt, dass, falls die Spalte nicht (mehr) existiert, keine Fehlermeldung produziert werden soll. Das ist hier hilfreich: falls man im Notebook eine Zelle mehrmals ausführt, würde ab dem zweiten Mal immer eine Fehlermeldung auftauchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205e0b6-f0a1-4228-b979-5ff9b4d4d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "# Einschränken des Datensatzes auf eine bestimmte Region\n",
    "#df = df[df[\"regio2\"]==\"Karlsruhe\"]\n",
    "#df = df[df[\"regio1\"]==\"Baden_Württemberg\"]\n",
    "\n",
    "df = df.drop([\"scoutId\", \"houseNumber\", \"geo_bln\", \"geo_krs\", \"date\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696d49a-8161-4b5c-ace8-6d695dd632dd",
   "metadata": {},
   "source": [
    "## Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001fa97-7e30-4692-8704-b7ea42614aff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Nicht-numerische Daten\n",
    "Wir schauen uns die Spalten, d.h. die *Attribute*, von denen einige später zu *Features* werden, genauer an. Um es etwas übersichtlicher zu halten schauen wir uns zunächst die nicht-numerischen und dann die numerischen Spalten an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11fa327-558f-4073-8765-27b1bd56ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=np.number).columns\n",
    "categorical_columns = df.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "df[categorical_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac732d3-e947-4746-acb3-970817ddc3f8",
   "metadata": {},
   "source": [
    "Wir erinnern uns: Wenn kategorielle Features mittels OneHot Encoding transformiert werden, so entsteht für jede Ausprägung eine neue Spalte. Die Anzahl der unterschiedlichen Ausprägungen gibt die Zeile \"unique\" an. Wenn wir also z.B. \"description\" (das ist ein Freitext Feld) mittels OneHot Encoding transformieren würden, würden wir einen DataFrame (also eine Datenmatrix) mit über 200,000 Spalten erhalten! Attribute mit zu vielen Ausprägungen schließen wir also zunächst aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50252622-0d85-4237-a2a3-c0f1ed66d028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop([\"street\", \"streetPlain\", \"description\", \"facilities\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af838120-14f6-4710-a28b-7ecd184464b3",
   "metadata": {},
   "source": [
    "Uns fällt ein Attribut \"firingTypes\" (laut Beschreibung die \"main energy source\") auf, das 132 verschiedene Ausprägungen hat. Das schauen wir uns genauer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a45d8-bf6b-4788-95bf-3dc42c955df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"firingTypes\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bf5a09-7205-4932-9658-cc7a518abb3e",
   "metadata": {},
   "source": [
    "Es gibt ein ähnliches Attribut heatingType, das hat aber deutlich weniger Ausprägungen. Wir schauen uns an, welche Ausprägungen es gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ca53a-a985-4d5c-9341-a1427a3d8cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"heatingType\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe5aa0-7174-46e5-816c-945a72b25b75",
   "metadata": {},
   "source": [
    "FiringTypes enthält *Kombinationen* von Ausprägungen von heatingTypes, getrennt durch Doppelpunkte. Wir entscheiden uns, das detailliertere von beiden Attributen auszuschließen, damit das entstehende Datenset nicht so groß wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48013606-e567-4153-ba46-8e3f9af97f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"firingTypes\", axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3fb785-eabf-4f58-83cc-84680df6c99f",
   "metadata": {},
   "source": [
    "Wir schauen noch einmal die kategoriellen Attribute an, die wir als Kandidaten für Features behalten möchten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfdd0f9-30af-461d-bba1-feaae457e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe(exclude=np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8404bb6-f44f-45c7-a5bb-389b8b75106a",
   "metadata": {},
   "source": [
    "Als nächstes schauen wir uns noch die Häufigkeitsverteilung der verschiedenen Ausprägungen an. Hier arbeiten wir mit der Methode .value_counts() von Pandas und erzeugen jeden Plot separat in einem Gitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ebdb4c-6eea-4d27-be7f-65d232216ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# n times n subplots\n",
    "n = int(np.ceil(np.sqrt(len(categorical_columns))))\n",
    "fig, axes = plt.subplots(nrows=n, ncols=n)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    plt.subplot(n, n, i+1)\n",
    "    if col in [\"regio2\", \"regio3\"]:  # regio2 und regio3 haben zu viele Ausprägungen\n",
    "        pass\n",
    "    else:\n",
    "        df[col].value_counts().plot(kind='bar', figsize=(20,20), title=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a6b8d-ee1d-4345-a515-e56f24bfa301",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe\n",
    "Beschreiben Sie die Verteilungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd686f-655c-4009-9e4a-b5f873d0f105",
   "metadata": {},
   "source": [
    "### Numerische Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c4a2cb-9d92-40d1-b5b2-0b628ff1a46b",
   "metadata": {},
   "source": [
    "Als nächstes schauen wir uns nun die numerischen Attribute genauer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172300e-8ab9-4a97-a807-35ea5ac82e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df.describe(include=np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d6bc0-da66-4856-bbdd-393a6899a1a1",
   "metadata": {},
   "source": [
    "Wir sehen, dass es einige extreme *Ausreißer* in den Daten gibt. So gibt es z.B. eine Wohnung mit monatlichen Nebenkosten von 146118 EUR, ein Objekt, das etwa 15 mio EUR Miete pro Monat kostet oder 111111m² Wohnfläche besitzt. Wir speichern uns die Namen der verdächtigen Spalten in einer Liste.\n",
    "Weiterhin sehen wir, dass das Feature telekomHybridUploadSpeed immer den Wert 10 hat oder leer ist, deshalb löschen wir es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262458d5-064d-41e1-9291-443a7ab73f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_columns = [\"serviceCharge\", \"totalRent\", \"yearConstructed\", \"noParkSpaces\", \"baseRent\", \"livingSpace\", \"noRooms\", \"numberOfFloors\", \"heatingCosts\", \"lastRefurbish\"]\n",
    "df.drop([\"telekomHybridUploadSpeed\"], axis=1, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7dea4e-b1da-4d84-a40f-1064e1712f73",
   "metadata": {},
   "source": [
    "Wir schließen explizit die Postleitzahl aus.\n",
    "\n",
    "## ✏ Aufgabe\n",
    "Glauben Sie, dass die PLZ ein gutes Feature wäre, d.h. hätte die PLZ Aussagekraft bezüglich der Kaltmiete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fe9ea-f3c1-41ca-9176-d57000635be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"regio3\",\"geo_plz\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519589b-6517-4589-bf20-8ccda146a019",
   "metadata": {},
   "source": [
    "### Untersuchung von Ausreißern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6be1b5-6e2a-46d5-9f3a-10b073c59b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly dauert lange, da der Datensatz groß ist\n",
    "#fig = make_subplots(rows=12, cols=1, subplot_titles=interesting_columns)\n",
    "#fig.update_layout(width=1200, height=1200)\n",
    "\n",
    "#for i, col in enumerate(interesting_columns):\n",
    "#    fig.add_trace(\n",
    "#        go.Box(x=df[col]),\n",
    "#        #row=i//4+1, col=i%4+1#\n",
    "#        row=i+1, col=1\n",
    "#    )\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5fa97-5987-4e66-b9c1-fcaebae40acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20,20))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, col in enumerate(interesting_columns):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    df[col].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8faa1-6a73-495e-af57-c98e4f7e6aa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datenbereinigung\n",
    "Das sind zu viele Ausreißer, als dass wir sie alle gesondert betrachten möchten. Wir schauen uns an, was passieren würde, wenn wir einfach die unteren und oberen 0.5% der Daten bezüglich dieser Attribute wegwerfen würden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfac57f-1b43-4e0f-b196-4c0aea2efb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[interesting_columns].quantile(0.995))\n",
    "display(df[interesting_columns].quantile(0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb9446-c638-4360-8cd8-936a1d701fbd",
   "metadata": {},
   "source": [
    "Das sieht nach einer gesünderen Verteilung aus. Wir wollen mit diesen Daten weiterarbeiten. Dazu erzeugen wir eine Kopie von df. Sonst würde df bei versehentlichem mehrmaligen Ausführen der Zelle immer kleiner werden (die Quantile würden auf dem neuen, kleineren df neu berechnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9fe5e-505d-42b1-88e6-317c5f31b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limits = df[interesting_columns].quantile(0.995)\n",
    "lower_limits = df[interesting_columns].quantile(0.005)\n",
    "\n",
    "df_reduced = df.copy()\n",
    "display(df_reduced.describe(include=np.number))\n",
    "\n",
    "# Für jede Spalte behalten wir: Daten die < (99.5%-Quantil) sind und > (0.5%-Quantil) sind ODER die NaN sind (damit befassen wir uns spaeter noch) \n",
    "for col in interesting_columns:\n",
    "    df_reduced = df_reduced[((df_reduced[col] <= upper_limits[col]) & (df_reduced[col] >= lower_limits[col])) | df_reduced[col].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0030b-1592-498f-b309-42b461a01b01",
   "metadata": {},
   "source": [
    "Wir haben nun also eine grobe Auswahl an Attributen getroffen, mit denen wir ab jetzt weiterarbeiten möchten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672a0c2-00fc-496b-bc13-3615545e595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20,20))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, col in enumerate(interesting_columns):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    df_reduced[col].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c355677-02e0-4461-b1af-57fdec28bd87",
   "metadata": {},
   "source": [
    "### Behandlung von fehlenden Datensätzen\n",
    "Wir haben eben schon gesehen, dass es einige NaN (=not a number) Felder in den Daten gibt. Bevor wir entscheiden, was wir damit tun, verschaffen wir uns einen Überblick, wie viele das etwa sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac0d16-2040-4c7b-a01a-e0bb46097b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_reduced.isna().sum()) # isna() wandelt jeden Wert in einen Boolschen Datentyp (0/1) um. sum() summiert diese Werte pro Spalte. Man erhält also die Anzahl der NaN Werte pro Spalte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d45cf-d199-45cd-b385-e59ecef1c5e9",
   "metadata": {},
   "source": [
    "Das sind z.T. sehr viele NaN Werte. Wenn wir alle Daten ignorieren würden, würden nicht mehr viele übrig bleiben. Wir verfolgen zunächst folgende Strategie: \n",
    "- Für numerische Werte wird für einen fehlenden Wert der Mittelwert der restlichen Werte eingesetzt.\n",
    "- Für nicht-numerische Werte wird für einen fehlenden Wert der häufigsten Wert (=Modus) der restlichen Werte eingesetzt.\n",
    "\n",
    "Zum Auffüllen der Werte stellt scikit-learn stellt die Klasse SimpleImputer bereit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8090fd-fdcd-415c-9852-222e26bceb5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Technisches Detail: wir müssen noch die Bool-Werte explizit konvertieren, sonst wirft der Imputer einen Fehler\n",
    "df_reduced = df_reduced.replace({False: 0, True: 1})\n",
    "\n",
    "numeric_columns = df_reduced.select_dtypes(include=np.number).columns\n",
    "numeric_columns = numeric_columns.drop(\"baseRent\") # Wenn das Label fehlt, wird es nicht ersetzt\n",
    "categorical_columns = df_reduced.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "imp_freq = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "df_reduced.loc[:,numeric_columns] = imp_mean.fit_transform(df_reduced[numeric_columns])\n",
    "df_reduced.loc[:,categorical_columns] = imp_freq.fit_transform(df_reduced[categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2796f3-5ffa-4257-bee6-e6aa17358e9e",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Korrelationen\n",
    "Wir erzeugen uns Scatter Plots um offensichtlich lineare oder nichtlineare Zusammenhänge zwischen einzelnen Features und der Zielvariable zu identifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485e865-b6ce-41f4-b257-1ddfad774850",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20,20))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, col in enumerate(interesting_columns):\n",
    "    #plt.subplot(4, 3, i+1)\n",
    "    df_reduced[[\"baseRent\",col]].plot.scatter(x=col, y=\"baseRent\", ax=axes[i//3,i%3], alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124aa6d-3cb4-4717-9b57-a636e786cc20",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe\n",
    "Schauen Sie sich die Korrelationen an. Was fällt Ihnen auf?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4049c-22db-4464-81ef-7252a04bdeb3",
   "metadata": {},
   "source": [
    "### OneHot Encoding\n",
    "Als nächstes transformieren wir die kategoriellen Spalten mittels OneHot-Encoding. Dafür benutzen wir die Pandas Funktion get_dummies() die in einem DataFrame für jede kategorielle Spalte das OneHot Encoding durchführt. D.h., für jede kategorielle Spalte entstehen mehrere 0/1-wertige Spalten, und zwar gerade so viele wie es Ausprägungen der Variable gibt. Das Ergebnis ist nun ein DataFrame, der weitaus mehr Spalten hat. Diese sind dafür aber alle numerisch, d.h. wir können sie für die lineare Regression (oder einen anderen ML Algorithmus verwenden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c0ef5-8672-4118-a194-102268a90b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.get_dummies(df_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71271e02-cef2-4605-912b-4c9dac00387e",
   "metadata": {},
   "source": [
    "Ein letzter Blick in die Daten ob alles funktioniert hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565fb00a-2389-4455-af59-233040e127b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1f490-7b35-4900-9999-b8d09e8f5bee",
   "metadata": {},
   "source": [
    "### Entfernen des Labels aus den Attributen\n",
    "WICHTIG: Wir möchten die Kaltmiete bzw. Gesamtmiete *vorhersagen*. Diese (und das davon direkt abgeleitete Attribut baseRentRange) müssen wir also auch noch ausschließen. Zuvor entfernen wir noch Datensätze, für die wir kein Label haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6dc717-5e6f-4051-9363-a90ec6cafba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reduced = df_reduced[df_reduced[\"baseRent\"].isna() == False] # Entfernen der Datensätze ohne Label\n",
    "y = df_reduced[\"baseRent\"]\n",
    "df_reduced = df_reduced.drop([\"baseRent\", \"totalRent\",\"baseRentRange\"], axis=1, errors=\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34174c-0a64-4e35-9caa-9a429aa1365f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Erstellen von Trainings- und Testset\n",
    "Bevor wir die Daten weiter bearbeiten, spalten wir sie in Trainings- und Testset auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66dbfe0-bb88-493c-8f16-bd554fe89e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_reduced, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af32299-d22a-40c7-9c5f-5ab3e8caa2b7",
   "metadata": {},
   "source": [
    "### Modelltraining\n",
    "Nun ist es soweit: Wir trainieren das Regressionsmodel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3de8c5-76c0-4c21-8d5e-973a0a7538a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "m = linear_model.LinearRegression()\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dac76a-142e-4243-8b41-1cfe4e08f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "r2_train = m.score(X_train, y_train)\n",
    "mse_train = mean_squared_error(y_train, m.predict(X_train))\n",
    "mae_train = mean_absolute_error(y_train, m.predict(X_train))\n",
    "r2_test = m.score(X_test, y_test)\n",
    "mse_test = mean_squared_error(y_test, m.predict(X_test))\n",
    "mae_test = mean_absolute_error(y_test, m.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1e6c9-e020-49f8-8d2a-0ddb789efa96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"R² Trainingsdaten: {r2_train}\")\n",
    "print(f\"Mean squared error Trainingsdaten: {mse_train}\")\n",
    "print(f\"Mean absolute error Trainingsdaten: {mae_train}\")\n",
    "print(f\"R² Testdaten: {r2_test}\")\n",
    "print(f\"Mean squared error Testdaten: {mse_test}\")\n",
    "print(f\"Mean absolute error Testdaten: {mae_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9d697-4d06-420d-8ea4-4bf4d9c10b06",
   "metadata": {},
   "source": [
    "Das Ergebnis der multiplen linearen Regression ist nicht so einfach zu visualisieren. Hier ein Versuch als Scatterplot zwischen der Größe der Wohnung und der Kaltmiete (blau) bzw. der vorhergesagten Kaltmiete (rot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f60dc-29ad-41d4-bcec-e585de9b14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[\"livingSpace\"], y_test, \"bo\", alpha=0.2)\n",
    "plt.plot(X_test[\"livingSpace\"], m.predict(X_test), \"ro\", alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90588268-7a80-428f-be94-2f2f96bf2f01",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 1\n",
    "Arbeiten Sie das Notebook durch und versuchen Sie die einzelnen Schritte nachzuvollziehen.\n",
    "\n",
    "## ✏ Aufgabe 2\n",
    "Wie ändert sich die Vorhersagequalität des Modells, wenn sie die Ausreißer nicht entfernen?\n",
    "Gehen Sie dazu zum Abschnitt Datenbereinigung, identifizieren sie den Code, der für das Entfernen der Ausreißer zuständig ist und kommentieren sie ihn aus.\n",
    "\n",
    "## ✏ Aufgabe 3\n",
    "Erstellen Sie ein Modell, das die Kaltmiete nur für eine bestimmte Region (z.B. Baden Württemberg, Karlsruhe, Karlsruhe und benachbarte Landkreise) vorhersagt. \n",
    "Am einfachsten geht das, indem Sie den Datensatz direkt nach dem Einlesen der Daten einschränken und dann alle weiteren Zellen unverändert ausführen. Wie ist die Vorhersagequalität auf Trainings- und Testdaten?\n",
    "\n",
    "## ✏ Aufgabe 4\n",
    "Erstellen Sie ein Modell mit anderen Features. Hier einige Vorschläge:\n",
    "- Nehmen Sie Features mit in das Modell auf, die wir am Anfang ausgeschlossen hatten und schauen sie, ob sie die Vorhersagegüte verbessern.\n",
    "- Nehmen Sie weniger Features. Die Vorhersagegüte (zumindest auf dem Trainingsdatensatz) wird dadurch zwar schlechter, doch auf kleinen Datensätzen sollten Sie ein robusteres Modell erhalten, d.h. eines, welches auf den Testdaten ähnlich gute Ergebnisse liefert wie auf den Trainingsdaten. Entweder wählen Sie per Hand geeignete Features aus oder Sie nehmen z.B. eine automatische Methode wie SelectKBest. Benutzen Sie dazu folgenden Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e33da-f31a-4cf6-b829-0ed9021bfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "feature_selection = SelectKBest(f_regression, k=50) # Ein Transformer, der per f_regression die 50 vielversprechendsten Features auswählt\n",
    "\n",
    "X_train = feature_selection.fit_transform(X_train, y_train)\n",
    "X_test = feature_selection.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda771e-6e4f-4b01-bcd1-59ba244dc64f",
   "metadata": {},
   "source": [
    "- Erstellen Sie sich neue Features durch Kombination oder Umformung vorhandener Features, z.B. polynomielle bzw. Interaktionsfeatures. Hier ein Code Beispiel, mit dem sie sich Interaktionsfeatures Bundesland x livingSpace erzeugen. Anschaulich bedeutet das: Der Koeffizient für das Feature livingSpace kann von Bundesland zu Bundesland unterschiedlich sein. Der Koeffizient für livingSpace ist anschaulich der Preis, der für einen zusätzlichen qm Wohnung mehr bezahlt werden muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f82eb35-fb6f-4eff-9880-ac215ea8b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree=2,interaction_only=True) # Ein Transformer, der Interaktionsfeatures vom (bis zu) Grad 2 erzeugt\n",
    "\n",
    "# Interaktionsfeatures: Bundesland x livingSpace\n",
    "bundeslaender_columns = \"regio1_\" + df[\"regio1\"].unique()\n",
    "for col in bundeslaender_columns:\n",
    "    features = pf.fit_transform(df_reduced[[col,\"livingSpace\"]])\n",
    "    df_reduced[col + \"_livingSpace\"] = features[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd92d7-e9f5-412c-9279-05fab8c898b5",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 5 🤯\n",
    "  - Sagen sie die Kaltmiete für Ihre Wohnung voraus. Überlegen Sie sich dazu, wie der Featurevektor für Ihre Wohnung aussehen würde, erstellen Sie einen DataFrame mit einer Zeile und wenden Sie das gelernte Modell mit .predict() an.\n",
    "  - Wie würde die Normalengleichung für das Problem aussehen? Versuchen Sie, statt des scikit-learn Modells das Modell \"per Hand\" zu trainieren, indem Sie die Normalengleichung aufstellen und nach den Modellparametern $w$ auflösen (z.B. mit numpy.linalg.solve). Machen Sie sich dazu zunächst die Problemdimensionen klar in Analogie zu den Formeln aus der Vorlesung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffbbd3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
