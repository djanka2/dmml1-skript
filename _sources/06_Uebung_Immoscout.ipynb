{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be6ae7b-a3a7-4fd0-baef-f24ebcc61d73",
   "metadata": {},
   "source": [
    "# Praxis√ºbung: Vorhersage von Wohnungsmieten\n",
    "Ziel dieser √úbung ist es, die Monatskaltmiete f√ºr eine Mietwohnung vorherzusagen anhand verschiedener Features wie Gr√∂√üe und Zustand der Wohnung, Nebenkosten, Bundesland etc. Laden Sie sich daf√ºr die Dateien \"immo_data.csv\" und \"immo_data_column_description.csv\" herunter. Alternativ k√∂nnen Sie sich die Datei immo_data.csv hier herunterladen: https://www.kaggle.com/corrieaar/apartment-rental-offers-in-germany (Account ben√∂tigt).\n",
    "\n",
    "Die Daten stammen von Immoscout24, der gr√∂√üten Immobilienplattform in Deutschland. Immoscout24 bietet sowohl Miet- als auch Kaufobjekte an, allerdings enthalten die Daten nur Angebote f√ºr Mietobjekte. Zu einem bestimmten Zeitpunkt wurden alle verf√ºgbaren Angebote von der Website abgefragt und gespeichert. Dieser Vorgang wurde dreimal wiederholt, so dass der Datensatz Angebote aus den Zeitr√§umen 2018-09-22, 2019-05-10 und 2019-10-08 enth√§lt.\n",
    "\n",
    "Der Datensatz enth√§lt die meisten wichtigen Eigenschaften, wie z.B. die Gr√∂√üe der Wohnfl√§che, die Miete, sowohl Kaltmiete als auch Gesamtmiete (falls zutreffend), die Lage (Stra√üe und Hausnummer, falls vorhanden, Postleitzahl und Bundesland), Energieart usw. Au√üerdem gibt es zwei Variablen, die l√§ngere Freitextbeschreibungen enthalten: Beschreibung mit einem Text, der das Angebot beschreibt, und Ausstattung mit einer Beschreibung aller verf√ºgbaren Einrichtungen, der neuesten Renovierung usw. Die Datumsspalte wurde hinzugef√ºgt, um den Zeitpunkt des Scrapings anzugeben.\n",
    "\n",
    "Wir m√∂chten unser Wissen √ºber lineare Regression und Datenanalyse an diesem Datensatz testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150fb200-f896-4b7e-b661-685019b7d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364906b-ce18-4703-be9f-f38deaf20f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"Daten/immo_data.csv\")\n",
    "desc = pd.read_csv(\"Daten/immo_data_column_description.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d32ef-fca4-4c05-a459-bed14963a292",
   "metadata": {},
   "source": [
    "Spaltenbeschreibungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ff03d-f2bd-4f82-9ab2-80cdc92b88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37498e-9622-46f6-952f-c6ad6cab53e9",
   "metadata": {},
   "source": [
    "Aus der Liste der Beschreibungen fallen uns einige Attribute auf, die doppelt auftreten oder (wahrscheinlich) keine Vorhersagekraft haben (eigentlich m√ºsste man das verifizieren!). Diese schlie√üen wir direkt aus, indem wir die \"drop\" Methode des DataFrame aufrufen und die entsprechenden Spaltennamen √ºbergeben. Das Argument errors=\"ignore\" besagt, dass, falls die Spalte nicht (mehr) existiert, keine Fehlermeldung produziert werden soll. Das ist hier hilfreich: falls man im Notebook eine Zelle mehrmals ausf√ºhrt, w√ºrde ab dem zweiten Mal immer eine Fehlermeldung auftauchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205e0b6-f0a1-4228-b979-5ff9b4d4d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "# Einschr√§nken des Datensatzes auf eine bestimmte Region\n",
    "#df = df[df[\"regio2\"]==\"Karlsruhe\"]\n",
    "#df = df[df[\"regio1\"]==\"Baden_W√ºrttemberg\"]\n",
    "\n",
    "df = df.drop([\"scoutId\", \"houseNumber\", \"geo_bln\", \"geo_krs\", \"date\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696d49a-8161-4b5c-ace8-6d695dd632dd",
   "metadata": {},
   "source": [
    "## Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001fa97-7e30-4692-8704-b7ea42614aff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Nicht-numerische Daten\n",
    "Wir schauen uns die Spalten, d.h. die *Attribute*, von denen einige sp√§ter zu *Features* werden, genauer an. Um es etwas √ºbersichtlicher zu halten schauen wir uns zun√§chst die nicht-numerischen und dann die numerischen Spalten an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11fa327-558f-4073-8765-27b1bd56ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=np.number).columns\n",
    "categorical_columns = df.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "df[categorical_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac732d3-e947-4746-acb3-970817ddc3f8",
   "metadata": {},
   "source": [
    "Wir erinnern uns: Wenn kategorielle Features mittels OneHot Encoding transformiert werden, so entsteht f√ºr jede Auspr√§gung eine neue Spalte. Die Anzahl der unterschiedlichen Auspr√§gungen gibt die Zeile \"unique\" an. Wenn wir also z.B. \"description\" (das ist ein Freitext Feld) mittels OneHot Encoding transformieren w√ºrden, w√ºrden wir einen DataFrame (also eine Datenmatrix) mit √ºber 200,000 Spalten erhalten! Attribute mit zu vielen Auspr√§gungen schlie√üen wir also zun√§chst aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50252622-0d85-4237-a2a3-c0f1ed66d028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop([\"street\", \"streetPlain\", \"description\", \"facilities\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af838120-14f6-4710-a28b-7ecd184464b3",
   "metadata": {},
   "source": [
    "Uns f√§llt ein Attribut \"firingTypes\" (laut Beschreibung die \"main energy source\") auf, das 132 verschiedene Auspr√§gungen hat. Das schauen wir uns genauer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a45d8-bf6b-4788-95bf-3dc42c955df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"firingTypes\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bf5a09-7205-4932-9658-cc7a518abb3e",
   "metadata": {},
   "source": [
    "Es gibt ein √§hnliches Attribut heatingType, das hat aber deutlich weniger Auspr√§gungen. Wir schauen uns an, welche Auspr√§gungen es gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ca53a-a985-4d5c-9341-a1427a3d8cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"heatingType\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe5aa0-7174-46e5-816c-945a72b25b75",
   "metadata": {},
   "source": [
    "FiringTypes enth√§lt *Kombinationen* von Auspr√§gungen von heatingTypes, getrennt durch Doppelpunkte. Wir entscheiden uns, das detailliertere von beiden Attributen auszuschlie√üen, damit das entstehende Datenset nicht so gro√ü wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48013606-e567-4153-ba46-8e3f9af97f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"firingTypes\", axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3fb785-eabf-4f58-83cc-84680df6c99f",
   "metadata": {},
   "source": [
    "Wir schauen noch einmal die kategoriellen Attribute an, die wir als Kandidaten f√ºr Features behalten m√∂chten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfdd0f9-30af-461d-bba1-feaae457e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe(exclude=np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8404bb6-f44f-45c7-a5bb-389b8b75106a",
   "metadata": {},
   "source": [
    "Als n√§chstes schauen wir uns noch die H√§ufigkeitsverteilung der verschiedenen Auspr√§gungen an. Hier arbeiten wir mit der Methode .value_counts() von Pandas und erzeugen jeden Plot separat in einem Gitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ebdb4c-6eea-4d27-be7f-65d232216ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# n times n subplots\n",
    "n = int(np.ceil(np.sqrt(len(categorical_columns))))\n",
    "fig, axes = plt.subplots(nrows=n, ncols=n)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    plt.subplot(n, n, i+1)\n",
    "    if col in [\"regio2\", \"regio3\"]:  # regio2 und regio3 haben zu viele Auspr√§gungen\n",
    "        pass\n",
    "    else:\n",
    "        df[col].value_counts().plot(kind='bar', figsize=(20,20), title=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a6b8d-ee1d-4345-a515-e56f24bfa301",
   "metadata": {},
   "source": [
    "## ‚úè Aufgabe\n",
    "Beschreiben Sie die Verteilungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd686f-655c-4009-9e4a-b5f873d0f105",
   "metadata": {},
   "source": [
    "### Numerische Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c4a2cb-9d92-40d1-b5b2-0b628ff1a46b",
   "metadata": {},
   "source": [
    "Als n√§chstes schauen wir uns nun die numerischen Attribute genauer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172300e-8ab9-4a97-a807-35ea5ac82e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df.describe(include=np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d6bc0-da66-4856-bbdd-393a6899a1a1",
   "metadata": {},
   "source": [
    "Wir sehen, dass es einige extreme *Ausrei√üer* in den Daten gibt. So gibt es z.B. eine Wohnung mit monatlichen Nebenkosten von 146118 EUR, ein Objekt, das etwa 15 mio EUR Miete pro Monat kostet oder 111111m¬≤ Wohnfl√§che besitzt. Wir speichern uns die Namen der verd√§chtigen Spalten in einer Liste.\n",
    "Weiterhin sehen wir, dass das Feature telekomHybridUploadSpeed immer den Wert 10 hat oder leer ist, deshalb l√∂schen wir es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262458d5-064d-41e1-9291-443a7ab73f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_columns = [\"serviceCharge\", \"totalRent\", \"yearConstructed\", \"noParkSpaces\", \"baseRent\", \"livingSpace\", \"noRooms\", \"numberOfFloors\", \"heatingCosts\", \"lastRefurbish\"]\n",
    "df.drop([\"telekomHybridUploadSpeed\"], axis=1, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7dea4e-b1da-4d84-a40f-1064e1712f73",
   "metadata": {},
   "source": [
    "Wir schlie√üen explizit die Postleitzahl aus.\n",
    "\n",
    "## ‚úè Aufgabe\n",
    "Glauben Sie, dass die PLZ ein gutes Feature w√§re, d.h. h√§tte die PLZ Aussagekraft bez√ºglich der Kaltmiete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fe9ea-f3c1-41ca-9176-d57000635be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"regio3\",\"geo_plz\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519589b-6517-4589-bf20-8ccda146a019",
   "metadata": {},
   "source": [
    "### Untersuchung von Ausrei√üern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6be1b5-6e2a-46d5-9f3a-10b073c59b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly dauert lange, da der Datensatz gro√ü ist\n",
    "#fig = make_subplots(rows=12, cols=1, subplot_titles=interesting_columns)\n",
    "#fig.update_layout(width=1200, height=1200)\n",
    "\n",
    "#for i, col in enumerate(interesting_columns):\n",
    "#    fig.add_trace(\n",
    "#        go.Box(x=df[col]),\n",
    "#        #row=i//4+1, col=i%4+1#\n",
    "#        row=i+1, col=1\n",
    "#    )\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5fa97-5987-4e66-b9c1-fcaebae40acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20,20))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, col in enumerate(interesting_columns):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    df[col].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8faa1-6a73-495e-af57-c98e4f7e6aa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datenbereinigung\n",
    "Das sind zu viele Ausrei√üer, als dass wir sie alle gesondert betrachten m√∂chten. Wir schauen uns an, was passieren w√ºrde, wenn wir einfach die unteren und oberen 0.5% der Daten bez√ºglich dieser Attribute wegwerfen w√ºrden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfac57f-1b43-4e0f-b196-4c0aea2efb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[interesting_columns].quantile(0.995))\n",
    "display(df[interesting_columns].quantile(0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb9446-c638-4360-8cd8-936a1d701fbd",
   "metadata": {},
   "source": [
    "Das sieht nach einer ges√ºnderen Verteilung aus. Wir wollen mit diesen Daten weiterarbeiten. Dazu erzeugen wir eine Kopie von df. Sonst w√ºrde df bei versehentlichem mehrmaligen Ausf√ºhren der Zelle immer kleiner werden (die Quantile w√ºrden auf dem neuen, kleineren df neu berechnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9fe5e-505d-42b1-88e6-317c5f31b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limits = df[interesting_columns].quantile(0.995)\n",
    "lower_limits = df[interesting_columns].quantile(0.005)\n",
    "\n",
    "df_reduced = df.copy()\n",
    "display(df_reduced.describe(include=np.number))\n",
    "\n",
    "# F√ºr jede Spalte behalten wir: Daten die < (99.5%-Quantil) sind und > (0.5%-Quantil) sind ODER die NaN sind (damit befassen wir uns spaeter noch) \n",
    "for col in interesting_columns:\n",
    "    df_reduced = df_reduced[((df_reduced[col] <= upper_limits[col]) & (df_reduced[col] >= lower_limits[col])) | df_reduced[col].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0030b-1592-498f-b309-42b461a01b01",
   "metadata": {},
   "source": [
    "Wir haben nun also eine grobe Auswahl an Attributen getroffen, mit denen wir ab jetzt weiterarbeiten m√∂chten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672a0c2-00fc-496b-bc13-3615545e595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20,20))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, col in enumerate(interesting_columns):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    df_reduced[col].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c355677-02e0-4461-b1af-57fdec28bd87",
   "metadata": {},
   "source": [
    "### Behandlung von fehlenden Datens√§tzen\n",
    "Wir haben eben schon gesehen, dass es einige NaN (=not a number) Felder in den Daten gibt. Bevor wir entscheiden, was wir damit tun, verschaffen wir uns einen √úberblick, wie viele das etwa sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac0d16-2040-4c7b-a01a-e0bb46097b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_reduced.isna().sum()) # isna() wandelt jeden Wert in einen Boolschen Datentyp (0/1) um. sum() summiert diese Werte pro Spalte. Man erh√§lt also die Anzahl der NaN Werte pro Spalte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d45cf-d199-45cd-b385-e59ecef1c5e9",
   "metadata": {},
   "source": [
    "Das sind z.T. sehr viele NaN Werte. Wenn wir alle Daten ignorieren w√ºrden, w√ºrden nicht mehr viele √ºbrig bleiben. Wir verfolgen zun√§chst folgende Strategie: \n",
    "- F√ºr numerische Werte wird f√ºr einen fehlenden Wert der Mittelwert der restlichen Werte eingesetzt.\n",
    "- F√ºr nicht-numerische Werte wird f√ºr einen fehlenden Wert der h√§ufigsten Wert (=Modus) der restlichen Werte eingesetzt.\n",
    "\n",
    "Zum Auff√ºllen der Werte stellt scikit-learn stellt die Klasse SimpleImputer bereit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8090fd-fdcd-415c-9852-222e26bceb5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Technisches Detail: wir m√ºssen noch die Bool-Werte explizit konvertieren, sonst wirft der Imputer einen Fehler\n",
    "df_reduced = df_reduced.replace({False: 0, True: 1})\n",
    "\n",
    "numeric_columns = df_reduced.select_dtypes(include=np.number).columns\n",
    "numeric_columns = numeric_columns.drop(\"baseRent\") # Wenn das Label fehlt, wird es nicht ersetzt\n",
    "categorical_columns = df_reduced.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "imp_freq = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "df_reduced.loc[:,numeric_columns] = imp_mean.fit_transform(df_reduced[numeric_columns])\n",
    "df_reduced.loc[:,categorical_columns] = imp_freq.fit_transform(df_reduced[categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2796f3-5ffa-4257-bee6-e6aa17358e9e",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Korrelationen\n",
    "Wir erzeugen uns Scatter Plots um offensichtlich lineare oder nichtlineare Zusammenh√§nge zwischen einzelnen Features und der Zielvariable zu identifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485e865-b6ce-41f4-b257-1ddfad774850",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20,20))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, col in enumerate(interesting_columns):\n",
    "    #plt.subplot(4, 3, i+1)\n",
    "    df_reduced[[\"baseRent\",col]].plot.scatter(x=col, y=\"baseRent\", ax=axes[i//3,i%3], alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124aa6d-3cb4-4717-9b57-a636e786cc20",
   "metadata": {},
   "source": [
    "## ‚úè Aufgabe\n",
    "Schauen Sie sich die Korrelationen an. Was f√§llt Ihnen auf?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4049c-22db-4464-81ef-7252a04bdeb3",
   "metadata": {},
   "source": [
    "### OneHot Encoding\n",
    "Als n√§chstes transformieren wir die kategoriellen Spalten mittels OneHot-Encoding. Daf√ºr benutzen wir die Pandas Funktion get_dummies() die in einem DataFrame f√ºr jede kategorielle Spalte das OneHot Encoding durchf√ºhrt. D.h., f√ºr jede kategorielle Spalte entstehen mehrere 0/1-wertige Spalten, und zwar gerade so viele wie es Auspr√§gungen der Variable gibt. Das Ergebnis ist nun ein DataFrame, der weitaus mehr Spalten hat. Diese sind daf√ºr aber alle numerisch, d.h. wir k√∂nnen sie f√ºr die lineare Regression (oder einen anderen ML Algorithmus verwenden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c0ef5-8672-4118-a194-102268a90b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.get_dummies(df_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71271e02-cef2-4605-912b-4c9dac00387e",
   "metadata": {},
   "source": [
    "Ein letzter Blick in die Daten ob alles funktioniert hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565fb00a-2389-4455-af59-233040e127b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1f490-7b35-4900-9999-b8d09e8f5bee",
   "metadata": {},
   "source": [
    "### Entfernen des Labels aus den Attributen\n",
    "WICHTIG: Wir m√∂chten die Kaltmiete bzw. Gesamtmiete *vorhersagen*. Diese (und das davon direkt abgeleitete Attribut baseRentRange) m√ºssen wir also auch noch ausschlie√üen. Zuvor entfernen wir noch Datens√§tze, f√ºr die wir kein Label haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6dc717-5e6f-4051-9363-a90ec6cafba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reduced = df_reduced[df_reduced[\"baseRent\"].isna() == False] # Entfernen der Datens√§tze ohne Label\n",
    "y = df_reduced[\"baseRent\"]\n",
    "df_reduced = df_reduced.drop([\"baseRent\", \"totalRent\",\"baseRentRange\"], axis=1, errors=\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34174c-0a64-4e35-9caa-9a429aa1365f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Erstellen von Trainings- und Testset\n",
    "Bevor wir die Daten weiter bearbeiten, spalten wir sie in Trainings- und Testset auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66dbfe0-bb88-493c-8f16-bd554fe89e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_reduced, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af32299-d22a-40c7-9c5f-5ab3e8caa2b7",
   "metadata": {},
   "source": [
    "### Modelltraining\n",
    "Nun ist es soweit: Wir trainieren das Regressionsmodel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3de8c5-76c0-4c21-8d5e-973a0a7538a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "m = linear_model.LinearRegression()\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dac76a-142e-4243-8b41-1cfe4e08f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "r2_train = m.score(X_train, y_train)\n",
    "mse_train = mean_squared_error(y_train, m.predict(X_train))\n",
    "mae_train = mean_absolute_error(y_train, m.predict(X_train))\n",
    "r2_test = m.score(X_test, y_test)\n",
    "mse_test = mean_squared_error(y_test, m.predict(X_test))\n",
    "mae_test = mean_absolute_error(y_test, m.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1e6c9-e020-49f8-8d2a-0ddb789efa96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"R¬≤ Trainingsdaten: {r2_train}\")\n",
    "print(f\"Mean squared error Trainingsdaten: {mse_train}\")\n",
    "print(f\"Mean absolute error Trainingsdaten: {mae_train}\")\n",
    "print(f\"R¬≤ Testdaten: {r2_test}\")\n",
    "print(f\"Mean squared error Testdaten: {mse_test}\")\n",
    "print(f\"Mean absolute error Testdaten: {mae_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9d697-4d06-420d-8ea4-4bf4d9c10b06",
   "metadata": {},
   "source": [
    "Das Ergebnis der multiplen linearen Regression ist nicht so einfach zu visualisieren. Hier ein Versuch als Scatterplot zwischen der Gr√∂√üe der Wohnung und der Kaltmiete (blau) bzw. der vorhergesagten Kaltmiete (rot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f60dc-29ad-41d4-bcec-e585de9b14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[\"livingSpace\"], y_test, \"bo\", alpha=0.2)\n",
    "plt.plot(X_test[\"livingSpace\"], m.predict(X_test), \"ro\", alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90588268-7a80-428f-be94-2f2f96bf2f01",
   "metadata": {},
   "source": [
    "## ‚úè Aufgabe 1\n",
    "Arbeiten Sie das Notebook durch und versuchen Sie die einzelnen Schritte nachzuvollziehen.\n",
    "\n",
    "## ‚úè Aufgabe 2\n",
    "Wie √§ndert sich die Vorhersagequalit√§t des Modells, wenn sie die Ausrei√üer nicht entfernen?\n",
    "Gehen Sie dazu zum Abschnitt Datenbereinigung, identifizieren sie den Code, der f√ºr das Entfernen der Ausrei√üer zust√§ndig ist und kommentieren sie ihn aus.\n",
    "\n",
    "## ‚úè Aufgabe 3\n",
    "Erstellen Sie ein Modell, das die Kaltmiete nur f√ºr eine bestimmte Region (z.B. Baden W√ºrttemberg, Karlsruhe, Karlsruhe und benachbarte Landkreise) vorhersagt. \n",
    "Am einfachsten geht das, indem Sie den Datensatz direkt nach dem Einlesen der Daten einschr√§nken und dann alle weiteren Zellen unver√§ndert ausf√ºhren. Wie ist die Vorhersagequalit√§t auf Trainings- und Testdaten?\n",
    "\n",
    "## ‚úè Aufgabe 4\n",
    "Erstellen Sie ein Modell mit anderen Features. Hier einige Vorschl√§ge:\n",
    "- Nehmen Sie Features mit in das Modell auf, die wir am Anfang ausgeschlossen hatten und schauen sie, ob sie die Vorhersageg√ºte verbessern.\n",
    "- Nehmen Sie weniger Features. Die Vorhersageg√ºte (zumindest auf dem Trainingsdatensatz) wird dadurch zwar schlechter, doch auf kleinen Datens√§tzen sollten Sie ein robusteres Modell erhalten, d.h. eines, welches auf den Testdaten √§hnlich gute Ergebnisse liefert wie auf den Trainingsdaten. Entweder w√§hlen Sie per Hand geeignete Features aus oder Sie nehmen z.B. eine automatische Methode wie SelectKBest. Benutzen Sie dazu folgenden Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e33da-f31a-4cf6-b829-0ed9021bfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "feature_selection = SelectKBest(f_regression, k=50) # Ein Transformer, der per f_regression die 50 vielversprechendsten Features ausw√§hlt\n",
    "\n",
    "X_train = feature_selection.fit_transform(X_train, y_train)\n",
    "X_test = feature_selection.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda771e-6e4f-4b01-bcd1-59ba244dc64f",
   "metadata": {},
   "source": [
    "- Erstellen Sie sich neue Features durch Kombination oder Umformung vorhandener Features, z.B. polynomielle bzw. Interaktionsfeatures. Hier ein Code Beispiel, mit dem sie sich Interaktionsfeatures Bundesland x livingSpace erzeugen. Anschaulich bedeutet das: Der Koeffizient f√ºr das Feature livingSpace kann von Bundesland zu Bundesland unterschiedlich sein. Der Koeffizient f√ºr livingSpace ist anschaulich der Preis, der f√ºr einen zus√§tzlichen qm Wohnung mehr bezahlt werden muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f82eb35-fb6f-4eff-9880-ac215ea8b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree=2,interaction_only=True) # Ein Transformer, der Interaktionsfeatures vom (bis zu) Grad 2 erzeugt\n",
    "\n",
    "# Interaktionsfeatures: Bundesland x livingSpace\n",
    "bundeslaender_columns = \"regio1_\" + df[\"regio1\"].unique()\n",
    "for col in bundeslaender_columns:\n",
    "    features = pf.fit_transform(df_reduced[[col,\"livingSpace\"]])\n",
    "    df_reduced[col + \"_livingSpace\"] = features[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd92d7-e9f5-412c-9279-05fab8c898b5",
   "metadata": {},
   "source": [
    "## ‚úè Aufgabe 5 ü§Ø\n",
    "  - Sagen sie die Kaltmiete f√ºr Ihre Wohnung voraus. √úberlegen Sie sich dazu, wie der Featurevektor f√ºr Ihre Wohnung aussehen w√ºrde, erstellen Sie einen DataFrame mit einer Zeile und wenden Sie das gelernte Modell mit .predict() an.\n",
    "  - Wie w√ºrde die Normalengleichung f√ºr das Problem aussehen? Versuchen Sie, statt des scikit-learn Modells das Modell \"per Hand\" zu trainieren, indem Sie die Normalengleichung aufstellen und nach den Modellparametern $w$ aufl√∂sen (z.B. mit numpy.linalg.solve). Machen Sie sich dazu zun√§chst die Problemdimensionen klar in Analogie zu den Formeln aus der Vorlesung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffbbd3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
