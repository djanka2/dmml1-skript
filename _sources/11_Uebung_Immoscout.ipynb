{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcec7130",
   "metadata": {},
   "source": [
    "# Praxisübung: Ensemble Modelle\n",
    "\n",
    "In dieser Übung wenden Sie die `scikit-learn` Implementierungen des Random Forest und des Gradient Boosting auf den Immoscout-Datensatz an. Es soll die Kaltmiete einer Wohnung vorhergesagt werden, d.h. es handelt sich um ein Regressionsmodell. Der Einfachheit halber ist der Code für die Vorverarbeitung gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5984c69f-bb7d-4bbd-b02f-b72284fa28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfaf7fef-4333-4009-ac69-9142ad497208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Daten/immo_data.csv\")\n",
    "desc = pd.read_csv(\"Daten/immo_data_column_description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4851f20-f4c7-4ab3-b727-ce537c55157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    \"\"\" Entfernen (vermeintlich) unwichtiger Spalten \"\"\"\n",
    "    return df.drop(\n",
    "        [\n",
    "            \"scoutId\",\n",
    "            \"houseNumber\",\n",
    "            \"geo_bln\",\n",
    "            \"geo_krs\",\n",
    "            \"geo_plz\",\n",
    "            \"date\",\n",
    "            \"street\",\n",
    "            \"streetPlain\",\n",
    "            \"description\",\n",
    "            \"facilities\",\n",
    "            \"regio3\",\n",
    "            \"firingTypes\",\n",
    "            \"telekomHybridUploadSpeed\",\n",
    "            \"totalRent\",\n",
    "            \"baseRentRange\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def remove_outliers(df, lower_limit=0.005, upper_limit=0.995):\n",
    "    \"\"\" Entfernen der (unteren und oberen) Ausreißer \"\"\"\n",
    "    dfc = df.copy()\n",
    "    columns_with_outliers = [\n",
    "        \"serviceCharge\",\n",
    "        \"yearConstructed\",\n",
    "        \"noParkSpaces\",\n",
    "        \"baseRent\",\n",
    "        \"livingSpace\",\n",
    "        \"noRooms\",\n",
    "        \"floor\",\n",
    "        \"numberOfFloors\",\n",
    "        \"heatingCosts\",\n",
    "        \"lastRefurbish\",\n",
    "    ]\n",
    "    \n",
    "    # Für jede Spalte behalten wir: Daten die < (99.5%-Quantil) sind und > (0.5%-Quantil) sind ODER die NaN sind (damit befassen wir uns spaeter noch) \n",
    "    upper_limits = df[columns_with_outliers].quantile(upper_limit)\n",
    "    lower_limits = df[columns_with_outliers].quantile(lower_limit)\n",
    "    \n",
    "    for colname in columns_with_outliers:\n",
    "        col = dfc[colname]\n",
    "        dfc = dfc[\n",
    "            ((col <= upper_limits[colname]) & (col >= lower_limits[colname]))\n",
    "            | col.isna()\n",
    "        ]\n",
    "    return dfc\n",
    "\n",
    "\n",
    "def remove_rows_with_NaN_target(df):\n",
    "    \"\"\" Entfernen der Datensätze ohne Label\"\"\"\n",
    "    return df[df[\"baseRent\"].isna() == False]\n",
    "\n",
    "\n",
    "def impute_NaNs(df):\n",
    "    \"\"\" Ersetzen von NaNs durch Mittelwert bzw. Modus \"\"\"\n",
    "    dfc = df.copy()\n",
    "    categorical_columns = dfc.select_dtypes(exclude=np.number).columns\n",
    "    imp_freq = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "    dfc.loc[:, categorical_columns] = imp_freq.fit_transform(dfc[categorical_columns])\n",
    "\n",
    "    numeric_columns = dfc.select_dtypes(include=np.number).columns\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    dfc.loc[:, numeric_columns] = imp_mean.fit_transform(dfc[numeric_columns])\n",
    "    return dfc\n",
    "\n",
    "\n",
    "def print_evaluation(pipeline_or_model, X_train, X_test, y_train, y_test, y_train_pred, y_test_pred, feature_names):\n",
    "    \"\"\" Ausgabe von R2-Wert, MSE und MAE für Trainings- und Testset \"\"\"\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    print(\n",
    "        f\"{pipeline_or_model} Evaluation:\\n\"\n",
    "        f\"{'':6} {'R²':>10} | {'MSE':>14} | {'MAE':>10} | {'rows':>8} | {'columns':>8}\\n\"\n",
    "        f\"{'Train':6} {r2_train:10.5f} | {mse_train:14.2f} | {mae_train:10.2f} | {X_train.shape[0]:8} | {X_train.shape[1]:8}\\n\"\n",
    "        f\"{'Test':6} {r2_test:10.5f} | {mse_test:14.2f} | {mae_test:10.2f} | {X_test.shape[0]:8} | {X_test.shape[1]:8}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "016fed6a-366d-41a2-83bc-e012c697c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1, random_state=42) Evaluation:\n",
      "               R² |            MSE |        MAE |     rows |  columns\n",
      "Train     0.84369 |       25629.80 |     104.07 |     7742 |      505\n",
      "Test      0.82320 |       28617.03 |     113.75 |     1936 |      505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Datenvorverarbeitung\n",
    "df_reduced = drop_columns(df.sample(10000, random_state=42))\n",
    "df_reduced = remove_outliers(df_reduced)\n",
    "df_reduced = remove_rows_with_NaN_target(df_reduced)\n",
    "df_reduced = impute_NaNs(df_reduced)\n",
    "df_reduced = pd.get_dummies(df_reduced)\n",
    "y = df_reduced.pop(\"baseRent\")\n",
    "\n",
    "# Training-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_reduced, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training und Hyperparametersuche\n",
    "parameters = {\"alpha\": [1e-3, 1e-1, 1, 10]}\n",
    "m = linear_model.Ridge(random_state=42)\n",
    "gs = GridSearchCV(m, parameters)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage mit dem besten Modell\n",
    "y_train_pred = gs.predict(X_train)\n",
    "y_test_pred = gs.predict(X_test)\n",
    "\n",
    "# Evaluation. Das beste Modell ist unter gs.best_estimator_ gespeichert. \n",
    "print_evaluation(gs.best_estimator_, X_train, X_test, y_train, y_test, y_train_pred, y_test_pred, feature_names=df_reduced.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f4169-c251-4d1f-a557-e23e7a365bb7",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 1\n",
    "Trainieren Sie einen Random Forest für das Wohnungsbeispiel. Experimentieren Sie mit den Parametern ``n_estimators``, ``max_depth`` und ``max_features``, um die Performance zu optimieren (entweder händisch oder mit GridSearchCV --> Vorsicht, Rechenzeit!). Was bedeuten die Parameter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effcbba4-12dc-4f79-8892-fa446af437ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d765e2e2-dd91-427b-af5e-8036b26f3cb8",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 2\n",
    "Trainieren Sie ein Gradient Boosting Regressionsmodell für das Wohnungsbeispiel. Experimentieren Sie mit den Parametern ``learning_rate``, ``max_leaf_nodes``, ``n_estimators``, ``max_depth`` und ``max_features``, um die Performance zu optimieren (entweder händisch oder mit GridSearchCV --> Vorsicht, Rechenzeit!). Was bedeuten die Parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3931d465-890d-448c-af5e-8f7a5305c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6547d0b7-0934-4209-b365-f5b3275151c7",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 3\n",
    "Welcher Algorithmus ist in folgendem Code realisiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a937e8ea-a462-4895-bc3c-fa48d79bf09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9878666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_trees = 500\n",
    "accuracy_scores = []\n",
    "\n",
    "Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)\n",
    "\n",
    "for k in range(n_trees):\n",
    "    X_train_, y_train_ = resample(X_train, y_train, replace=True)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train_, y_train_)\n",
    "    \n",
    "    Y_pred[k] = clf.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "y_pred, count = mode(Y_pred)\n",
    "print(accuracy_score(y_test, y_pred[0]))\n",
    "print(np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89e48f-a718-426e-aaed-a7a8d553460a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
