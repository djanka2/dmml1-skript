{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13990fde-efbd-40db-b89a-3a6c90938b5c",
   "metadata": {},
   "source": [
    "# Praxisübung: Logistische Regression und Gradientenabstieg\n",
    "\n",
    "In dieser Übung trainieren Sie ein kleines logistisches Regressionsmodell mittels Gradientenabstieg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effe1f6-5092-433f-992e-e304e2f1464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa29ef-14a1-4086-a00a-a0653164b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdatensatz. Dieser ist im folgenden fest, d.h. die Verlustfunktion bezieht sich \n",
    "# auf einen festen Trainingsdatensatz und wir fassen sie nur noch als Funktion von w auf.\n",
    "\n",
    "# 2 Features: die erste Spalte sorgt dafür, dass der Koeffizienten w_0 (\"Intercept\") mitgeschätzt wird\n",
    "X = np.array([[1,1,1,1,1,1,1,1,1,1,1],\n",
    "              [-1,-0.8,-0.6,-0.4,-0.2,0,0.2,0.4,0.6,0.8,1]]).T\n",
    "y = np.array([0,0,0,0,0,0,1,1,1,1,1])\n",
    "\n",
    "print(f\"X = \\n{X}\")\n",
    "plt.plot(X[:,1],y, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a7471-6b87-45fb-b887-c4f94a2e8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistische Funktion\n",
    "def logistic(w, X):\n",
    "    return 1/(1+np.exp(-X@w))\n",
    "\n",
    "# Kreuzentropie Funktion\n",
    "def L(w, X=X, y=y):\n",
    "    y_hat = logistic(w, X)\n",
    "    return -np.mean(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
    "\n",
    "# Ableitung der Kreuzentropie nach w\n",
    "def dLdw(w, X=X, y=y):\n",
    "    y_hat = logistic(w, X)\n",
    "    # Elementweise Multiplikation und spaltenweiser Mittelwert ergibt Gradientenvektor\n",
    "    return np.mean((y_hat-y)[:,np.newaxis]*X, axis=0)\n",
    "\n",
    "# Algorithmus: Gradientenabstieg zur Bestimmung der Parameter w\n",
    "# w0: Startwert/-schätzung für w\n",
    "# alpha: Schrittweite\n",
    "# n_iter: Anzahl Iterationen\n",
    "# Return: w (die Koeffizienten, die L auf den Trainingsdaten minimieren)\n",
    "def gradient_descent(w0, alpha, n_iter):\n",
    "    w = w0\n",
    "    for k in range(n_iter):\n",
    "        # Gib Zielfunktionswert in jeder 1000. Iteration aus\n",
    "        if k % 1000 == 0:\n",
    "            print(L(w))\n",
    "        w = w - alpha * dLdw(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adecd512-8a97-4c93-91ac-941be4fdaaa3",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 1\n",
    "Lassen Sie das Gradientenverfahren mit Schrittweite 1 für 10000 Iterationen laufen. \n",
    "Geben Sie am Ende die gelernten Koeffizienten aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad28b69-876e-45cb-9557-c5c51bffdaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19cbde-c19e-484b-8688-ebd25bce1d04",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 2\n",
    "Sagen Sie die Wahrscheinlichkeit und die Klasse (Schwellwert 0.5) für die Trainingsdaten vorher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16973709-2943-46b0-8e75-29462b54ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6949ea-26b0-4b44-a859-9d0ae0145c12",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 3\n",
    "Trainieren Sie ein logistisches Regressionsmodell mit scikit-learn für denselben Datensatz. Was bedeutet der Parameter ``penalty=\"none\"``? Lassen Sie sich auch hier die Koeffizienten ausgeben und sagen Sie Wahrscheinlichkeiten und Klasse für die Trainingsdaten vorher. Beobachten Sie Unterschiede zum Modell oben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e90822-e9e1-41d6-92df-6ddcfaa88a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegenprobe mit scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression(fit_intercept=False, penalty=\"none\")\n",
    "\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
