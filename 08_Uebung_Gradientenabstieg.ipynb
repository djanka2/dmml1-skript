{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13990fde-efbd-40db-b89a-3a6c90938b5c",
   "metadata": {},
   "source": [
    "# Übung: Logistische Regression und Gradientenabstieg\n",
    "\n",
    "In dieser Übung beschäftigen Sie sich mit Modellfunktion und Verlustfunktion der logistischen Regression und trainieren ein kleines logistisches Regressionsmodell mittels Gradientenabstieg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 1\n",
    "In der folgenden Aufgabe sollen Sie ein Gefühl für die Modellfunktion und die Verlustfunktion der logistischen Regression entwickeln. Dafür betrachten wir drei verschiedene Modelle $f_1$, $f_2$, $f_3$, $f_4$ mit unterschiedlichen Parametern $w_0$ und $w_1$:\n",
    "\n",
    "\\begin{align*}\n",
    "    f_1&: w_0=0, w_1=5\\\\\t\t\n",
    "    f_2&: w_0=0, w_1=10\\\\\n",
    "    f_3&: w_0=1, w_1=10\\\\\n",
    "    f_4&: w_0=1, w_1=-7\\\\\n",
    "\\end{align*}\n",
    "Weiterhin sei folgender Datensatz aus 4 Punkten gegeben:\n",
    "\\begin{align*}\n",
    "    x &= (-0.4,-0.2,0,0.2)\\\\\n",
    "    y &= (0,0,1,1)\n",
    "\\end{align*}\n",
    "\n",
    "1. Berechnen Sie die Modellvorhersage von Modell $f_3$ für den Datensatz.\n",
    "2. Plotten Sie die vier Modellfunktionen. Wie kann man die Werte $w_0$ und $w_1$ graphisch interpretieren?\n",
    "3. Berechnen Sie die Kreuzentropie-Verlustfunktion für das Modell $f_3$. Schreiben Sie den Term auf.\n",
    "4. Berechnen Sie die Entscheidungsgrenze für das Modell $f_3$ für den Schwellwert $B=0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispielcode: Gradientenabstieg für logistische Regression\n",
    "Im folgenden ist beispielhaft ein Gradientenabstiegsverfahren für die logistische Regression implementiert. Weiter unten gibt es Aufgaben dazu :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effe1f6-5092-433f-992e-e304e2f1464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa29ef-14a1-4086-a00a-a0653164b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdatensatz. Dieser ist im folgenden fest, d.h. die Verlustfunktion bezieht sich \n",
    "# auf einen festen Trainingsdatensatz und wir fassen sie nur noch als Funktion von w auf.\n",
    "\n",
    "# 2 Features: die erste Spalte sorgt dafür, dass der Koeffizienten w_0 (\"Intercept\") mitgeschätzt wird\n",
    "X = np.array([[1,1,1,1,1,1,1,1,1,1,1],\n",
    "              [-1,-0.8,-0.6,-0.4,-0.2,0,0.2,0.4,0.6,0.8,1]]).T\n",
    "y = np.array([0,0,0,0,1,0,1,1,1,1,1])\n",
    "\n",
    "print(f\"X = \\n{X}\")\n",
    "plt.plot(X[:,1],y, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a7471-6b87-45fb-b887-c4f94a2e8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistische Funktion\n",
    "def logistic(w, X):\n",
    "    return 1/(1+np.exp(-X@w))\n",
    "\n",
    "# Kreuzentropie Funktion\n",
    "def L(w, X=X, y=y):\n",
    "    y_hat = logistic(w, X)\n",
    "    return -np.mean(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
    "\n",
    "# Ableitung der Kreuzentropie nach w\n",
    "def dLdw(w, X=X, y=y):\n",
    "    y_hat = logistic(w, X)\n",
    "    # Elementweise Multiplikation und spaltenweiser Mittelwert ergibt Gradientenvektor\n",
    "    return np.mean((y_hat-y)[:,np.newaxis]*X, axis=0)\n",
    "\n",
    "# Algorithmus: Gradientenabstieg zur Bestimmung der Parameter w\n",
    "# w0: Startwert/-schätzung für w\n",
    "# alpha: Schrittweite\n",
    "# n_iter: Anzahl Iterationen\n",
    "# Return: w (die Koeffizienten, die L auf den Trainingsdaten minimieren)\n",
    "def gradient_descent(w0, alpha, n_iter):\n",
    "    w = w0\n",
    "    for k in range(n_iter):\n",
    "        # Gib Zielfunktionswert in jeder 1000. Iteration aus\n",
    "        if k % 1000 == 0:\n",
    "            print(L(w))\n",
    "        w = w - alpha * dLdw(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adecd512-8a97-4c93-91ac-941be4fdaaa3",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 2\n",
    "Lassen Sie das Gradientenverfahren mit Schrittweite 1 für 100 Iterationen laufen. \n",
    "Geben Sie am Ende die gelernten Koeffizienten aus und plotten Sie das Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad28b69-876e-45cb-9557-c5c51bffdaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19cbde-c19e-484b-8688-ebd25bce1d04",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 3\n",
    "Sagen Sie die Wahrscheinlichkeit und die Klasse (Schwellwert 0.5) für die Trainingsdaten vorher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16973709-2943-46b0-8e75-29462b54ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6949ea-26b0-4b44-a859-9d0ae0145c12",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 4\n",
    "Trainieren Sie ein logistisches Regressionsmodell mit scikit-learn für denselben Datensatz. Was bedeutet der Parameter ``penalty=\"none\"``? Lassen Sie sich auch hier die Koeffizienten ausgeben, plotten Sie das Modell, und sagen Sie Wahrscheinlichkeiten und Klasse für die Trainingsdaten vorher. Beobachten Sie Unterschiede zum Modell oben? Was passiert, wenn Sie das Gradientenverfahren aus Aufgabe 2 für 10000 Iterationen laufen lassen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
