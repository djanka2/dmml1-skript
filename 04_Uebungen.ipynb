{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungen\n",
    "\n",
    "## ✏ Aufgabe 1\n",
    "Erzeugen Sie Plots der folgenden Funktionen:\n",
    "- $f_1(x)=5x^2$\n",
    "- $f_2(x)=x^4+7x^3+5x^2-17x+3$\n",
    "  \n",
    "im Bereich zwischen $x=-5$ und $x=5$ (für $f_1$) bzw. $x=-6$ und $x=3$ (für $f_2$).\n",
    "\n",
    "## ✏ Aufgabe 2 (1D Gradientenabstieg)\n",
    "In dieser Übung sollen Sie einen Gradientenabstiegsalgorithmus mit fester Schrittweite implementieren. Sie können entweder das folgende Codegerüst als Basis nehmen oder die Implementierung aus dem Skript übernehmen. In jedem Fall müssen Sie für die Funktionen $f_1$ und $f_2$ (und deren Ableitung) eigene Python Funktionen `def f(x)` und `def df(x)` schreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\" Function to minimize \"\"\"\n",
    "    return #TODO\n",
    "\n",
    "def df(x):\n",
    "    \"\"\" Derivative of the function to minimize \"\"\"\n",
    "    return #TODO\n",
    "\n",
    "def gradient_descent(func, derv, alpha, x0, n_steps):\n",
    "    \"\"\" Perform n_steps iterations of gradient descent and print iterates \"\"\"\n",
    "    x_history = [x0]\n",
    "\n",
    "    #TODO\n",
    "    \n",
    "    return x_history\n",
    "\n",
    "#x0 = # Startwert\n",
    "#alpha = # Schrittweite\n",
    "x_history = gradient_descent(func=f, derv=df, alpha=alpha, x0=x0, n_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern Sie für jede Iteration den aktuellen Wert $x^{[k]}$ und geben sie die Historie dieser Werte zurück.\n",
    "\n",
    "Wenden Sie den Gradientenabstieg (nacheinander) auf die beiden Funktionen aus Aufgabe 1 an:\n",
    "\n",
    "Analysieren Sie dann das Verhalten des Algorithmus. Gehen Sie dabei wie folgt vor:\n",
    "1. Plotten Sie jeweils die Folge der Iterierten $x^{[k]}$ für $k=0,1,2,\\dots$ zusammen mit der Funktion (Aufgabe 1) in ein Diagramm (im Skript ist das für ein Beispiel gemacht).\n",
    "2. Wählen Sie einen Startwert $x^{[0]}$ aus dem Bereich, in dem sie die Funktionen geplottet haben. Wählen Sie als Schrittweite $\\alpha=0.01$. Wie viele Schritte benötigen Sie, um nahe an die Lösung zu gelangen?\n",
    "3. Versuchen Sie als nächstes, die Schrittweite $\\alpha$ in Schritten von $0.01$ zu erhöhen. Wie verändert sich die Konvergenzgeschwindigkeit? Ab welcher Schrittweite konvergiert der Algorithmus nicht mehr?\n",
    "4. $f_2$ besitzt jeweils ein lokales und ein globales Minimum. Können Sie Konvergenz des Algorithmus zu beiden Minima beobachten?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✏ Aufgabe 3 (mehrdimensionaler Gradientenabstieg)\n",
    "Betrachten Sie die Funktion $g:\\mathbb{R}^{10}\\rightarrow\\mathbb{R}$ mit\n",
    "\\begin{align*}\n",
    "g(x)=x^Tx,\n",
    "\\end{align*}\n",
    "\n",
    "d.h. $x$ ist ein 10-dimensionaler Vektor. Implementieren Sie den Gradientenabstieg für diese Funktion und lassen Sie ihn 100 Schritte laufen. Verwenden Sie dabei den Startwert $(10,10,\\dots,10)^T$.\n",
    "Probieren Sie die drei Schrittweiten $\\alpha_1=0.001$, $\\alpha_2=0.1$ und $\\alpha_3=1$ aus. Plotten Sie die Folge der Funktionswerte $g(x^{[k]})$ für $k=0,1,2,\\dots 100$ für alle drei Schrittweiten in einem Diagramm. Welche Schrittweite ist am besten geeignet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
